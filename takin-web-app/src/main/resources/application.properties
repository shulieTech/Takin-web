# 服务端口, 前缀
server.port=10008
server.servlet.context-path=/takin-web

# 激活环境
spring.profiles.active=local

# flyway 数据库版本升级控制
spring.flyway.enabled=false
# 验证错误时删除数据, 关闭
spring.flyway.clean-on-validation-error=false
# 允许清除数据操作, 不允许
spring.flyway.clean-disabled=true
spring.flyway.url=${spring.datasource.url}
spring.flyway.user=${spring.datasource.username}
spring.flyway.password=${spring.datasource.password}
spring.flyway.table=t_migration_history
spring.flyway.baseline-on-migrate=true
spring.flyway.baseline-version=1
# 迁移的时候, 是否校验
# 是否校验每个迁移过的文件?
# 检验迁移过的和现有的内容是否一样
spring.flyway.validate-on-migrate=false

# 文件上传
spring.servlet.multipart.max-file-size=204800KB
spring.servlet.multipart.max-request-size=204800KB

# amdb data url 配置
amdb.url.amdb=http://${amdb.out.url:127.0.0.1:10032}
amdb.url.pradar=http://${pradar.out.url:127.0.0.1:8080}

#check health
management.health.solr.enabled=false
management.health.elasticsearch.enabled=false

server.tomcat.accesslog.enabled=true
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D %{User-Agent}i

## build info ##
takin.web.url=http://localhost:10008/takin-web
takin.web.version=@project.version@
# 升级文档地址
takin.web.upgrade.addr=@upgrade.doc@

#takin.cloud.url=http://${takin-cloud.out.url:127.0.0.1}/takin-cloud
takin.cloud.url=http://10.125.18.246:10010/takin-cloud

## mybatis plus config ##
mybatis-plus.configuration.map-underscore-to-camel-case=true
mybatis-plus.mapper-locations[0]=classpath*:com/pamirs/takin/entity/mapper/**/*.xml
mybatis-plus.mapper-locations[1]=classpath*:mappers/**/*.xml

takin.config.nacos.enbale=nacos
takin.config.nacos.addr=192.168.1.99:8848

takin.config.zk.addr=192.168.1.154:2181
spring.performance.influxdb.database=performance
spring.influxdb.url=http://${resource.influxdb.host:127.0.0.1}:${resource.influxdb.port:8086}
spring.influxdb.user=pradar
spring.influxdb.database=base
spring.influxdb.password=pradar
# job配置
# job.clear.day.time= 0
# job 分片数配置
# job.sharding.total.Count=3
#link.fix.enable=false
# 黑名单自动修复
#blacklist.data.fix.enable=false
# agent 版本配置
#takin-web.application.new-agent= 0
# 白名单文件
spring.config.whiteListPath=/opt/tro/conf/tro-web/api/confcenter/wbmnt/query/
# 大文件下载
remote.client.download.uri=/api/bigfile/download


# file url path and takin-cloud be consistent
file.upload.url=${takin.cloud.url}
file.upload.script.path=${data.path:/data}/scriptfile
file.upload.tmp.path=${data.path:/data}/scriptfile/temp
#file.ops_script.path=${data.path:/data}/ops_nfs_dir/
# appdeploy
#file.ops_script.deploy_user=
# user module
file.upload.user.data.dir= ${data.path:/data}/tmp

takin.license=5b06060a-17cb-4588-bb71-edd7f65035aa


remote.call.auto.join.white=true
# 登录次数限制
takin.login.num=3
# 登录超次数后，延迟时间
takin.login.time=1

# 调用amdb的单次边数量
call.amdb.eagle_size=300

#logging.level.io.shulie.takin.web.data.mapper.mysql=debug

takin.data.path=${data.path}

# 是否是内部预发环境 1-是 0=不是
takin.inner.pre=0

# 设置登录超时时间，默认24小时
login.expire.time=86400

pdf.path=/data/nfs_dir/takin/web/report/pdf
# 非租户管理员需要过滤的菜单,通过code过滤,逗号分割
tenant.menu.filter: securityCenter_trafficConfig,securityCenter_keysConfig

ds.database.url=
agent.ds.compareVersion=

# cloud添加后增加的配置
takin.config.zk.timeOut=15000
report.aggregation.interval=5s
# 脚本文件配置
script.temp.path=${script.path}/temp
script.path=${data.path:/data}/scriptfile
#nfs检测
nfs.warning.percent=85
pradar.upload.client.dir=${user.dir}/pradar-upload-client
console.url=http://kither.vip3gz.91tunnel.com/takin-web/

#cloud influxdb
cloud.influxdb.url: http://192.168.1.129:8086
cloud.influxdb.user: pradar
cloud.influxdb.password: pradar
cloud.influxdb.database: crank

takin-web.server.config={"loginType": 3}
maven.pull.job.enable: true
agent.manager.host=""

xxl.job.admin.addresses=http://10.125.18.246:8103/xxl-job-admin

### xxl-job, access token
xxl.job.accessToken=default_token

### xxl-job executor appname
xxl.job.executor.appname=takin-web
### xxl-job executor registry-address: default use address to registry , otherwise use ip:port if address is null
xxl.job.executor.address=
### xxl-job executor server-info
xxl.job.executor.ip=
xxl.job.executor.port=9998
### xxl-job executor log-path
xxl.job.executor.logpath=/Users/dijia/temp/applogs/xxl-job/jobhandler
### xxl-job executor log-retention-days
xxl.job.executor.logretentiondays=30




#web??

#tro-web ???????????

data.path=/Users/shulie/Documents/test/temp/nfs

#?????????

file.ops_script.path=${data.path}/ops_nfs_dir/

fast.debug.upload.log.path=${data.path}/debug/log/

fast.debug.call.stack.path=${data.path}/debug/callstack/

#??????

#job????

job.sharding.total.Count=1



#???IP????

resource.mysql.host=10.125.18.246

##########e2e###########

#??????????0???????????????? 1?????????????

patrol.engine.type=0

e2e.engine.type=0

#????????????????????????????300??

e2e.error.alert.interval=120

#???????????????????????????300??

e2e.count.data.interval=120

#?????????? ????

patrol.bottleneck.detail=http://web-ui-svc/tro/#/bottleneckTable/bottleneckDetails?exceptionId=

e2e.bottleneck.detail=http://web-ui-svc/tro/#/pro/bottleneckTable/bottleneckDetails?exceptionId=

#??????????????

patrol.tech_node.middleware_name=http,dubbo,rocketmq,rabbitmq,kafka,elasticjob,grpc,apache-kafka,mysql,tomcat,redis,httpclient4,google-guava,ons,sto-event,apache-dubbo

##########e2e###########


#??????

takin.front.url.system=#/configCenter/systemInfo

#????

takin.front.url.default=#/dashboard

#????
#######################??????????????####################

#??????

#????????
#tomcat????

server.tomcat.basedir=${data.path}

server.tomcat.max-threads=1000

server.tomcat.max-connections=500

#mysql??

spring.datasource.url=jdbc:mysql://${resource.mysql.host}:4306/trodb?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=UTF-8&useSSL=false&allowMultiQueries=true

spring.datasource.type=com.alibaba.druid.pool.DruidDataSource

spring.datasource.driverClassName=com.mysql.jdbc.Driver

spring.datasource.username=stresstest

spring.datasource.password=ca$hc0Wa

spring.datasource.druid.initialSize=20

spring.datasource.druid.minIdle=20

spring.datasource.druid.maxActive=100

spring.datasource.druid.maxWait=60000

spring.datasource.druid.timeBetweenEvictionRunsMillis=60000

spring.datasource.druid.minEvictableIdleTimeMillis=30000

spring.datasource.druid.validationQuery=select 'x'

spring.datasource.druid.testWhileIdle=true

spring.datasource.druid.testOnBorrow=false

spring.datasource.druid.poolPreparedStatements=true

spring.datasource.druid.maxPoolPreparedStatementPerConnectionSize=20

spring.datasource.druid.filters=stat,wall,slf4j

spring.datasource.druid.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000

#redis??

spring.redis.cluster.nodes=10.125.128.119:32728,10.125.128.117:32728,10.125.11.126:32982,10.125.128.93:32553,10.125.11.124:32996,10.125.11.125:32996
spring.redis.password=ca$hc0Wa
spring.redis.timeout=10000
spring.redis.jedis.pool.max-active=100
spring.redis.jedis.pool.max-wait=-1
###############################################################



#nfs??

#
# pressure.image.name=harbor.dcos.xixian.unicom.local/skyeye-platform/stresstest/pressure-engine:2.0.0

pressure.callback.ignore.type=100,200,303

pressure.node.heartbeat.expireTime=300


#4?20?????

## ????

apisix.web.keyUrl=

### #??token

apisix.web.token=


### # ???????,??code??

liantong.skyEye.path=https://10.125.18.246

liantong.menu=true

### ????
traffic.recorder.query.service.url=https://tianyan.test.tg.unicom.local/callEvolution/jgyj/getRpcAnalysis
traffic.recorder.query.max.size=50000
#traffic.recorder.trace.clearScript: requestMap = jsonToMap(removeB(requestBody));\nMap resultMap = new HashMap();\n resultMap.put(\"mobile\",requestMap.get(\"mobile\"));\n resultMap.put(\"password\",requestMap.get(\"password\"));\n return resultMap;
#traffic.recorder.trace.clearScript: requestMap = jsonToMap(requestBody);\nMap resultMap = new HashMap(); \n  if (requestMap.get(\"userName\") == null) { \n requestMap.put(\"userName\",\" \")} \n if (requestMap.get(\"captcha\") == null) { \n requestMap.put(\"captcha\",\" \")} \n resultMap.put(\"userName\",requestMap.get(\"userName\"));\n resultMap.put(\"captcha\",requestMap.get(\"captcha\"));\n return resultMap;
traffic.recorder.trace.clearScript: requestMap = jsonToMap(requestBody);\nMap resultMap = new HashMap(); \n  if (requestMap.get(\"userName\") != null) { \n resultMap.put(\"userName\",requestMap.get(\"userName\"));} \n if (requestMap.get(\"captcha\") != null) { \n resultMap.put(\"captcha\",requestMap.get(\"captcha\"));} \n return resultMap;

# ??
traffic.recorder.trace.fetch.sqlColumns=transactionId traceId,applicationId appName,requestUrl serviceName,requestMethod methodName,requestHeader,requestBody,responseHeader,responseBody,statusCode resultCode,collectorAcceptTime startTime
traffic.recorder.trace.fetch.sqlPart=from d_ccm_http_msg where applicationId =:appName  and requestUrl like concat('%',:serviceName)  and systemCode =:systemCode and collectorAcceptTime > :recordBeginTime and collectorAcceptTime <= :recordEndTime
traffic.recorder.trace.rpcTypes=''
traffic.recorder.service=unicomTrafficRecorderService
traffic.recorder.clickhouse.url=jdbc:clickhouse://10.161.136.73:48123,10.161.136.74:48123,10.161.136.75:48123,10.161.136.76:48123,10.161.225.172:48123,10.161.225.173:48123,10.161.225.174:48123,10.161.225.175:48123/default

traffic.recorder.clickhouse.userName=stresstest
traffic.recorder.clickhouse.password=stresstest@Tianyan2022
takin.clickhouse.url=jdbc:clickhouse://10.161.55.19:48123,10.161.55.17:48123/default
takin.clickhouse.userName=default
takin.clickhouse.password=Li+pMiwwLzy63k5H

agent.ds.useNewVersionShadowTemplate=true

takin.collector.url=http://127.0.0.1:10086
takin.sre.url=http://192.168.54.103:8501